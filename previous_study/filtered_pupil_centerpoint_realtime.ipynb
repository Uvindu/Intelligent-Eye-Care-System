{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from gaze_tracking import GazeTracking\n",
    "\n",
    "%matplotlib inline\n",
    "m=6\n",
    "cam_index=0\n",
    "initialize_time=20 #change by observing the cam detection time\n",
    "cam_setection_time=16\n",
    "k=cam_index\n",
    "\n",
    "\n",
    "def high(img):\n",
    "    #img = cv2.resize(img,(int(img.shape[1]*m),int(img.shape[0]*m)))\n",
    "    img = cv2.resize(img,(240,100))\n",
    "    dst = cv2.fastNlMeansDenoising(img,None,200.0, 7, 21)\n",
    "    #dst2 = cv2.fastNlMeansDenoising(dst,None,20.0,7,21)\n",
    "    \n",
    "    #dst3 = cv2.fastNlMeansDenoising(dst2,None,50,7,21)\n",
    "    '''\n",
    "    dst4 = cv2.fastNlMeansDenoisingColored(dst3,None,10,10,7,21)\n",
    "    dst5 = cv2.fastNlMeansDenoisingColored(dst4,None,10,10,7,21)\n",
    "    dst6 = cv2.fastNlMeansDenoisingColored(dst5,None,10,10,7,21)\n",
    "    dst7 = cv2.fastNlMeansDenoisingColored(dst6,None,10,10,7,21)\n",
    "    dst8 = cv2.fastNlMeansDenoisingColored(dst7,None,10,10,7,21)\n",
    "    dst9 = cv2.fastNlMeansDenoisingColored(dst8,None,10,10,7,21)\n",
    "    dst10 = cv2.fastNlMeansDenoisingColored(dst9,None,10,10,7,21)'''\n",
    "\n",
    "    return dst #RGB    \n",
    "\n",
    "def blob(im,center):\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 270  # The dot in 20pt font has area of about 30\n",
    "    params.filterByColor = 1\n",
    "    #params.blobColor = 255\n",
    "    params.filterByCircularity = 0\n",
    "    params.filterByConvexity = 0\n",
    "    params.filterByInertia = 0\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(im)\n",
    "    im_with_keypoints=cv2.cvtColor(im,cv2.COLOR_GRAY2BGR)\n",
    "    try:\n",
    "        pt1=im.shape[1]//2-keypoints[0].pt[0]\n",
    "        pt2=im.shape[1]//2-keypoints[0].pt[1]\n",
    "        my=cv2.KeyPoint(im.shape[1]//2,im.shape[0]//2,0.2)\n",
    "    except IndexError:pass\n",
    "    #(100,180)\n",
    "    #cv2.putText(im, \"point: (%d,%d) \" %(pt1,pt2), (10,10), cv2.FONT_HERSHEY_DUPLEX, 0.5, (147, 58, 31), 1)\n",
    "    #im_with_keypoints = cv.drawKeypoints(im, keypoints[0:1], np.array([]), (255,0,255), 0)\n",
    "    try:\n",
    "        b=cv2.drawKeypoints(im, [keypoints[0]], np.array([]), (255,255,0), 0)\n",
    "        pupil_mid=np.array(keypoints[0].pt)\n",
    "        im_with_keypoints = cv2.drawKeypoints(im, [center,keypoints[0]], np.array([]), (255,255,0), 0)\n",
    "    except UnboundLocalError:\n",
    "        try:\n",
    "            pupil_mid=np.array(keypoints[0].pt)\n",
    "            im_with_keypoints = cv2.drawKeypoints(im, [keypoints[0]], np.array([]), (255,255,0), 0)\n",
    "        except:return im_with_keypoints,pupil_mid\n",
    "    except IndexError:\n",
    "        try:\n",
    "            pupil_mid=np.array(center.pt)\n",
    "            im_with_keypoints = cv2.drawKeypoints(im, [center], np.array([]), (255,255,0), 0)\n",
    "        except:return im_with_keypoints,pupil_mid\n",
    "    return im_with_keypoints,pupil_mid\n",
    "\n",
    "def checkside(pupil_left,pupil_right,center_left,center_right,thr):\n",
    "    center_left=np.array(center_left.pt)\n",
    "    center_right=np.array(center_right.pt)\n",
    "    dist1=(pupil_left[0]-center_left[0])**3\n",
    "    dist2=(pupil_right[0]-center_right[0])**3\n",
    "    if dist1>thr and dist2>thr:\n",
    "        return 'LEFT'\n",
    "    elif dist1<-thr and dist2<-thr:\n",
    "        return 'RIGHT'\n",
    "    else:\n",
    "        return 'MIDDLE'\n",
    "\n",
    "def find_center(t):\n",
    "    start=time.time()\n",
    "    center_left=cv2.KeyPoint()\n",
    "    center_right=cv2.KeyPoint()\n",
    "    center_left.pt=(0,0)\n",
    "    center_right.pt=(0,0)\n",
    "    left_=[]\n",
    "    right_=[]\n",
    "    gaze = GazeTracking()\n",
    "    webcam = cv2.VideoCapture(k)\n",
    "    i=0\n",
    "    print('camera detection period (initialize time should be greater than this) :',abs(time.time()-start),'\\ninitialize_time :',initialize_time)  \n",
    "    while abs(time.time()-start)<t:\n",
    "        # We get a new frame from the webcam\n",
    "        _, frame = webcam.read()\n",
    "\n",
    "        # We send this frame to GazeTracking to analyze it\n",
    "        try:\n",
    "            gaze.refresh(frame)\n",
    "        except:print('frame_fucked')\n",
    "        flag=0\n",
    "        try:\n",
    "            left=gaze.eye_left.frame\n",
    "            right=gaze.eye_right.frame\n",
    "            try:\n",
    "                #res_left = cv2.resize(left, (10*left.shape[1],10*left.shape[0])) \n",
    "                res_left=left\n",
    "                res_right=right\n",
    "            except: print('RESIZE ___')\n",
    "\n",
    "            flag=1\n",
    "        except:\n",
    "            print('pupil detection failed')\n",
    "            try:\n",
    "                landmarks = self._predictor(frame, faces[0])\n",
    "            except:\n",
    "                #print(\"landmarks detection failed\")\n",
    "                try:\n",
    "                    faces= self._face_detector(frame)\n",
    "                except:print(\"face_detection failed\")\n",
    "        if flag==1:\n",
    "            i+=1\n",
    "            frame1,pupil_left=blob(high(res_left),center_left)\n",
    "            frame2,pupil_right=blob(high(res_right),center_right)\n",
    "            frame2 = cv2.resize(frame2, (frame1.shape[1],frame1.shape[0])) \n",
    "            frame=np.hstack((high(res_left),high(res_right)))\n",
    "            left_.append(pupil_left)\n",
    "            right_.append(pupil_right)\n",
    "            cv2.putText(frame, 'Calibrating ... ', (30,30), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "        else:\n",
    "            frame=np.zeros((170,170))\n",
    "        cv2.imshow(\"Demo\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    left_=np.array(left_)\n",
    "    right_=np.array(right_)\n",
    "    try:\n",
    "        left_=tuple(np.average(left_,axis=0))\n",
    "        right_=tuple(np.average(right_,axis=0))\n",
    "    except:\n",
    "        print('check initialize_time')\n",
    "        return 0\n",
    "    center_left.pt=left_\n",
    "    center_right.pt=right_\n",
    "    return center_left,center_right\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%\n",
      "camera detection period (initialize time should be greater than this) : 2.607917547225952 \n",
      "initialize_time : 20\n",
      "camera detection period (initialize time should be greater than this) : 3.6630728244781494 \n",
      "initialize_time : 20\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Demonstration of the GazeTracking library.\n",
    "Check the README.md for complete documentation.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "from gaze_tracking import GazeTracking\n",
    "\n",
    "gaze = GazeTracking()\n",
    "webcam = cv2.VideoCapture(k)\n",
    "i=0\n",
    "print('%%%%')\n",
    "center_left,center_right=find_center(initialize_time)\n",
    "s=time.time()\n",
    "while True:\n",
    "    # We get a new frame from the webcam\n",
    "    _, frame = webcam.read()\n",
    "\n",
    "    # We send this frame to GazeTracking to analyze it\n",
    "    try:\n",
    "        gaze.refresh(frame)\n",
    "    except:print('frame_fucked')\n",
    "    flag=0\n",
    "    try:\n",
    "        left=gaze.eye_left.frame\n",
    "        right=gaze.eye_right.frame\n",
    "        try:\n",
    "            #res_left = cv2.resize(left, (10*left.shape[1],10*left.shape[0])) \n",
    "            res_left=left\n",
    "            res_right=right\n",
    "        except: print('RESIZE ___')\n",
    "        \n",
    "        flag=1\n",
    "    except:\n",
    "        print('pupil detection failed')\n",
    "        try:\n",
    "            landmarks = self._predictor(frame, faces[0])\n",
    "        except:\n",
    "            #print(\"landmarks detection failed\")\n",
    "            try:\n",
    "                faces= self._face_detector(frame)\n",
    "            except:print(\"face_detection failed\")\n",
    "    \n",
    "    if flag==1:\n",
    "        i+=1\n",
    "        cv2.imwrite('E:/ML_IP/ML_projects/Eye_tracking/gaze/eye_frames_2/left/%d__thres_49.jpg'%i,res_left)\n",
    "        \n",
    "        frame1,pupil_left=blob(high(res_left),center_left)\n",
    "        frame2,pupil_right=blob(high(res_right),center_right)\n",
    "        side=checkside(pupil_left,pupil_right,center_left,center_right,1100)\n",
    "        frame2 = cv2.resize(frame2, (frame1.shape[1],frame1.shape[0])) \n",
    "        frame=np.hstack((frame1,frame2))\n",
    "        #print(frame.shape)\n",
    "        cv2.putText(frame, side, (30,30), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "        #cv2.imwrite('eye_frames/eyes_test/%d.jpg'%i,frame)\n",
    "    else:\n",
    "        frame=np.zeros((170,170))\n",
    "        #frame=gaze.annotated_frame()\n",
    "\n",
    "    cv2.imshow(\"Demo\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "    if time.time()-s>40:\n",
    "        center_left,center_right=find_center(30)\n",
    "        s=time.time()\n",
    "        webcam = cv2.VideoCapture(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
